<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DRE-Bench</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Truly Assessing Fluid Intelligence of Large Language Models through Dynamic Reasoning Evaluation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/datasets/yang5114/DRE-Bench" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Data</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/yangyue5114/DRE-Bench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Leaderboard Link. -->
                <span class="link-block">
                  <a href="./build/leaderboard.html" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-trophy"></i>
                    </span>
                    <span>Leaderboard</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->
<section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/fig1-intro-new-516_00.png" alt="" style="width: 100%; height: auto;">
        <h2 class="subtitle has-text-centered">
        </h2>
      </div>
    </div>
  </section>

<!-- Paper abstract -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in large language models (LLMs) have demonstrated impressive reasoning capacities that mirror human-like thinking. However, whether LLMs
            possess genuine fluid intelligence (i.e., the ability to reason abstractly and generalize rules in novel situations) remains an open question. Existing reasoning
            benchmarks either focus on domain-specific knowledge (crystallized intelligence) or lack interpretability. To address these limitations, we propose DRE-Bench, 
            a dynamic reasoning evaluation benchmark grounded in a hierarchical cognitive framework. DRE-Bench consists of 36 abstract reasoning tasks organized across
            four cognitive levels, with each task featuring multiple dynamic variants that test the same underlying latent rule. This design enables fine-grained, interpretable,
            and reliable assessments of fluid intelligence. We evaluate a range of state-of-the-art LLMs, including both general LLMs (GPT-4o, Claude 3.7) and reasoning
            LLMs (o1, DeepSeek-R1, QwQ, Skywork-OR1). Experimental results reveal that although most LLMs achieve competent and robust performance in low-level cognition, 
            they struggle with high-level cognition and exhibit limited generalization as task complexity grows. Our findings highlight the gap between current LLMs and
            true human-like fluid intelligence and offer a new path for systematically tracking reasoning progress in LLMs.
          </p>
        </div>
        <h3 class="title is-3">Introduction</h3>
        <div class="content has-text-justified">
          <p>
            the contributions of this paper are summarized as follows. 1) We propose an abstract
            reasoning benchmark with a cognition hierarchy, providing a more structural and comprehensive
            system to analyze the LLMs' true fluid intelligence. 2) We develop a verifiable and scalable data
            engine to dynamically generate abstract reasoning data with various complexities, by designing
            a generator and solver for each task. 3) We perform comprehensive evaluations on a variety of
            popular LLMs, indicating that the existing LLMs still struggle to solve the reasoning problem of
            high cognitive levels. Existing LLMs may not have truly internalized the underlying reasoning rules,
            which highlights that they remain far from achieving true fluid intelligence. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/images/fig2-method-tree-single-rectangle_00.png" alt="MY ALT TEXT" style ="width: 80%; height: auto;"/>
        <h2 class="subtitle has-text-centered">
          Specific abstract reasoning tasks across our four cognitive levels. For each task example, we visualize two pairs of input and output, corresponding to two different values of the dynamic variable. The arrows are annotated with the value range of the variable, and darker colors indicate higher complexity.
        </h2>
      </div>
      <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/images/fig2-method-new-three-step_00.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          DRE-Bench Data Generation Pipeline: (1) Annotators identify task-specific constraints and rules, writing a generator and solver function. (2) The generator produces dynamic input data based on different variable values. (3) The solver analyzes and computes ground-truth output for each input.
        </h2>
      </div>
      <!-- <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div> -->
     <!-- <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div> -->
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->

<section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <h2 class="title is-3" style = "text-align: center;">Experiment</h2>
            <div class="content has-text-justified">
              <p>
                in this section, we evaluate state-of-the-art large language models and investigate the following
                research questions through experimental results: i) How do current LLMs perform in abstract
                reasoning across different cognitive levels? ii) As the complexity of dynamic data
                increases, how will the LLM's performance change? iii) Based on the performance
                of different LLMs across various cognitive dimensions, to what extent has the model's intelligence
                level reached? iv) Is inference time scaling, visual information, and number of training
                context samples, truly effective for abstract reasoning tasks? 
              </p>
            </div>
          </div>
        </div>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-image1">
            <div style="text-align: center;">
              <img src="static/images/merged_4_plots_larger516_00.png" alt="Image 1" style="width: 100%; height: auto;"/>
              <h2 class="subtitle has-text-centered">
                Model performance curves under varying complexities in four cognitive reasoning levels.
              </h2>
            </div>
          </div>
          <div class="item item-image2">
            <div style="text-align: center;">
              <img src="static/images/scatter_combined_levels(2)_00.png" alt="Image 2" style="width: 100%; height: auto;"/>
              <h2 class="subtitle has-text-centered">
                Scatter plots of model accuracy versus variance in cognitive reasoning levels and corre-sponding tasks, where points closer to the upper-left indicate higher accuracy and greater stability.
              </h2>
            </div>
          </div>
          <div class="item item-image3">
            <div style="text-align: center;">
              <img src="static/images/ablation_train_num_00.png" alt="Image 3" style="width: 60%; height: auto;"/>
              <h2 class="subtitle has-text-centered">
                Accuracy of DeepSeek-R1 on different numbers of in-context training samples.
              </h2>
            </div>
          </div>
          <div class="item item-image4">
            <div style="text-align: center;">
              <img src="static/images/ablation_time_o1_performance_metrics(1)_00.png" alt="Image 4" style="width: 100%; height: auto;"/>
              <h2 class="subtitle has-text-centered">
                Changing trend in o1's accuracy and inference time as task complexity increases.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
